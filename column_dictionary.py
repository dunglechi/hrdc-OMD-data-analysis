"""
Smart Column Dictionary
T·ª± ƒë·ªông ph√°t hi·ªán v√† qu·∫£n l√Ω √Ω nghƒ©a c√°c c·ªôt v·ªõi AI
"""

import pandas as pd
import google.generativeai as genai
from typing import Dict, Any, Optional
import json
import streamlit as st

class ColumnDictionary:
    """
    Qu·∫£n l√Ω √Ω nghƒ©a c√°c c·ªôt v·ªõi AI inference v√† user editing
    """
    
    def __init__(self, df: pd.DataFrame, model):
        """
        Initialize Column Dictionary
        
        Args:
            df: DataFrame c·∫ßn ph√¢n t√≠ch
            model: Gemini model instance
        """
        self.df = df
        self.model = model
        self.dictionary = {}  # {column_name: column_info}
    
    def auto_detect_meanings(self) -> Dict[str, Dict[str, Any]]:
        """
        S·ª≠ d·ª•ng Gemini AI ƒë·ªÉ t·ª± ƒë·ªông ƒëo√°n √Ω nghƒ©a t·∫•t c·∫£ c√°c c·ªôt
        OPTIMIZED: Batch processing - ph√¢n t√≠ch t·∫•t c·∫£ c·ªôt trong 1 l·∫ßn g·ªçi API
        
        Returns:
            Dict[column_name, column_info]
        """
        if not self.model:
            # Fallback: basic inference without AI
            return self._basic_inference()
        
        try:
            # Batch inference - all columns at once
            self.dictionary = self._batch_infer_all_columns()
        except Exception as e:
            print(f"Batch inference failed: {e}, falling back to basic inference")
            self.dictionary = self._basic_inference()
        
        return self.dictionary
    
    def _batch_infer_all_columns(self) -> Dict[str, Dict[str, Any]]:
        """
        Ph√¢n t√≠ch T·∫§T C·∫¢ c√°c c·ªôt trong 1 l·∫ßn g·ªçi API (nhanh h∆°n nhi·ªÅu)
        
        Returns:
            Dict[column_name, column_info]
        """
        # Prepare summary for all columns
        columns_data = []
        
        for col in self.df.columns:
            col_data = self.df[col]
            sample_values = col_data.dropna().head(3).tolist()
            
            col_summary = {
                'name': col,
                'dtype': str(col_data.dtype),
                'unique': int(col_data.nunique()),
                'missing': int(col_data.isnull().sum()),
                'sample': sample_values
            }
            
            # Add stats for numeric
            if col_data.dtype in ['int64', 'float64']:
                col_summary['stats'] = {
                    'min': float(col_data.min()) if not pd.isna(col_data.min()) else None,
                    'max': float(col_data.max()) if not pd.isna(col_data.max()) else None,
                    'mean': float(col_data.mean()) if not pd.isna(col_data.mean()) else None
                }
            
            columns_data.append(col_summary)
        
        # Build batch prompt
        prompt = f"""
Ph√¢n t√≠ch T·∫§T C·∫¢ c√°c c·ªôt d·ªØ li·ªáu sau v√† ƒëo√°n √Ω nghƒ©a:

**Danh s√°ch c·ªôt**:
{json.dumps(columns_data, ensure_ascii=False, indent=2)}

**Y√™u c·∫ßu**:
Cho M·ªñI c·ªôt, ƒëo√°n:
1. √ù nghƒ©a ti·∫øng Vi·ªát (ng·∫Øn g·ªçn, d·ªÖ hi·ªÉu)
2. √ù nghƒ©a ti·∫øng Anh
3. Category (financial/demographic/behavioral/temporal/identifier/other)
4. Confidence (0.0-1.0)
5. Reasoning (ng·∫Øn g·ªçn)

**QUAN TR·ªåNG - Thu·∫≠t ng·ªØ VNPT Vi·ªÖn th√¥ng**:
- **TKC** = T√†i Kho·∫£n Ch√≠nh (KH√îNG PH·∫¢I "Ti·ªÅn khuy·∫øn c√°o")
- **Total_TKC** = T·ªïng s·ªë ti·ªÅn trong t√†i kho·∫£n ch√≠nh
- **PHONE/SDT** = S·ªë ƒëi·ªán tho·∫°i kh√°ch h√†ng
- **TINH** = T·ªânh/Th√†nh ph·ªë
- **NGAY_KICH_HOAT** = Ng√†y k√≠ch ho·∫°t d·ªãch v·ª•
- **ACCOUNT_AGE** = Tu·ªïi t√†i kho·∫£n (s·ªë ng√†y t·ª´ khi k√≠ch ho·∫°t)
- **SERVICE** = Lo·∫°i d·ªãch v·ª• (Data, Voice, SMS...)
- **ARPU** = Average Revenue Per User (Doanh thu TB/user)

**L∆∞u √Ω**:
- ∆Øu ti√™n domain knowledge VNPT tr√™n
- N·∫øu kh√¥ng ch·∫Øc ‚Üí confidence th·∫•p (<0.7)
- Reasoning ph·∫£i gi·∫£i th√≠ch r√µ t·∫°i sao

**Tr·∫£ v·ªÅ JSON** (object v·ªõi key l√† t√™n c·ªôt):
{{
    "COLUMN_NAME_1": {{
        "meaning_vi": "√ù nghƒ©a ti·∫øng Vi·ªát",
        "meaning_en": "English meaning",
        "category": "financial",
        "confidence": 0.95,
        "reasoning": "L√Ω do"
    }},
    "COLUMN_NAME_2": {{
        ...
    }}
}}

**JSON**:
"""
        
        try:
            response = self.model.generate_content(prompt)
            
            # Extract JSON
            json_text = self._extract_json(response.text)
            results = json.loads(json_text)
            
            # Add metadata
            for col, info in results.items():
                info['user_edited'] = False
                info['original_ai_meaning'] = info.get('meaning_vi', col)
            
            return results
            
        except Exception as e:
            print(f"Error in batch inference: {e}")
            raise
    
    def _infer_single_column(self, column: str) -> Dict[str, Any]:
        """
        ƒêo√°n √Ω nghƒ©a m·ªôt c·ªôt b·∫±ng Gemini AI
        
        Args:
            column: T√™n c·ªôt
        
        Returns:
            Dict ch·ª©a meaning, category, confidence, reasoning
        """
        # Prepare column analysis data
        col_data = self.df[column]
        dtype = str(col_data.dtype)
        sample_values = col_data.dropna().head(5).tolist()
        unique_count = col_data.nunique()
        missing_count = col_data.isnull().sum()
        
        # Statistics for numeric columns
        stats = {}
        if col_data.dtype in ['int64', 'float64']:
            stats = {
                'min': float(col_data.min()) if not pd.isna(col_data.min()) else None,
                'max': float(col_data.max()) if not pd.isna(col_data.max()) else None,
                'mean': float(col_data.mean()) if not pd.isna(col_data.mean()) else None
            }
        
        # Build prompt for Gemini
        prompt = f"""
Ph√¢n t√≠ch c·ªôt d·ªØ li·ªáu v√† ƒëo√°n √Ω nghƒ©a:

**Th√¥ng tin c·ªôt**:
- T√™n c·ªôt: {column}
- Ki·ªÉu d·ªØ li·ªáu: {dtype}
- S·ªë gi√° tr·ªã unique: {unique_count}
- S·ªë gi√° tr·ªã missing: {missing_count}
- M·∫´u d·ªØ li·ªáu: {sample_values}
{f"- Th·ªëng k√™: {stats}" if stats else ""}

**Y√™u c·∫ßu**:
D·ª±a tr√™n t√™n c·ªôt (c√≥ th·ªÉ vi·∫øt t·∫Øt), ki·ªÉu d·ªØ li·ªáu, v√† gi√° tr·ªã m·∫´u, h√£y ƒëo√°n:
1. √ù nghƒ©a c·ªßa c·ªôt (ti·∫øng Vi·ªát, ng·∫Øn g·ªçn, d·ªÖ hi·ªÉu)
2. √ù nghƒ©a ti·∫øng Anh
3. Danh m·ª•c d·ªØ li·ªáu (financial/demographic/behavioral/temporal/identifier/other)
4. ƒê·ªô tin c·∫≠y (0.0-1.0)
5. L√Ω do ƒëo√°n nh∆∞ v·∫≠y

**L∆∞u √Ω**:
- TKC = T√†i Kho·∫£n Ch√≠nh (ph·ªï bi·∫øn trong vi·ªÖn th√¥ng VN)
- PHONE = S·ªë ƒëi·ªán tho·∫°i
- TINH = T·ªânh/Th√†nh ph·ªë
- N·∫øu kh√¥ng ch·∫Øc, confidence th·∫•p h∆°n

**Tr·∫£ v·ªÅ JSON**:
{{
    "meaning_vi": "√ù nghƒ©a ti·∫øng Vi·ªát",
    "meaning_en": "English meaning",
    "category": "financial|demographic|behavioral|temporal|identifier|other",
    "confidence": 0.95,
    "reasoning": "L√Ω do ng·∫Øn g·ªçn"
}}

**JSON**:
"""
        
        try:
            response = self.model.generate_content(prompt)
            
            # Extract JSON from response
            json_text = self._extract_json(response.text)
            result = json.loads(json_text)
            
            # Add metadata
            result['user_edited'] = False
            result['original_ai_meaning'] = result['meaning_vi']
            
            return result
            
        except Exception as e:
            print(f"Error inferring column {column}: {e}")
            return self._basic_column_info(column)
    
    def _basic_inference(self) -> Dict[str, Dict[str, Any]]:
        """Fallback inference without AI"""
        result = {}
        for col in self.df.columns:
            result[col] = self._basic_column_info(col)
        return result
    
    def _basic_column_info(self, column: str) -> Dict[str, Any]:
        """Basic column info without AI"""
        col_data = self.df[column]
        
        # Simple category detection
        category = 'other'
        if 'phone' in column.lower() or 'tel' in column.lower():
            category = 'identifier'
        elif 'date' in column.lower() or 'time' in column.lower():
            category = 'temporal'
        elif 'price' in column.lower() or 'amount' in column.lower() or 'tkc' in column.lower():
            category = 'financial'
        elif 'name' in column.lower() or 'address' in column.lower():
            category = 'demographic'
        
        return {
            'meaning_vi': column.replace('_', ' ').title(),
            'meaning_en': column.replace('_', ' ').title(),
            'category': category,
            'confidence': 0.5,
            'reasoning': 'Fallback inference (AI not available)',
            'user_edited': False,
            'original_ai_meaning': column
        }
    
    def _extract_json(self, text: str) -> str:
        """Extract JSON from markdown or text"""
        import re
        
        # Try to find JSON in code blocks
        json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', text, re.DOTALL)
        if json_match:
            return json_match.group(1)
        
        # Try to find JSON directly
        json_match = re.search(r'\{.*\}', text, re.DOTALL)
        if json_match:
            return json_match.group(0)
        
        raise ValueError("No JSON found in response")
    
    def update_meaning(self, column: str, meaning_vi: str, meaning_en: str = None):
        """
        C·∫≠p nh·∫≠t √Ω nghƒ©a do user s·ª≠a
        
        Args:
            column: T√™n c·ªôt
            meaning_vi: √ù nghƒ©a ti·∫øng Vi·ªát
            meaning_en: √ù nghƒ©a ti·∫øng Anh (optional)
        """
        if column in self.dictionary:
            self.dictionary[column]['meaning_vi'] = meaning_vi
            if meaning_en:
                self.dictionary[column]['meaning_en'] = meaning_en
            self.dictionary[column]['user_edited'] = True
        else:
            # Create new entry
            self.dictionary[column] = {
                'meaning_vi': meaning_vi,
                'meaning_en': meaning_en or meaning_vi,
                'category': 'other',
                'confidence': 1.0,
                'reasoning': 'User defined',
                'user_edited': True,
                'original_ai_meaning': ''
            }
    
    def get_meaning(self, column: str, lang='vi') -> str:
        """
        L·∫•y √Ω nghƒ©a c·ªßa m·ªôt c·ªôt
        
        Args:
            column: T√™n c·ªôt
            lang: Ng√¥n ng·ªØ ('vi' ho·∫∑c 'en')
        
        Returns:
            str: √ù nghƒ©a c·ªßa c·ªôt
        """
        if column not in self.dictionary:
            return column
        
        key = 'meaning_vi' if lang == 'vi' else 'meaning_en'
        return self.dictionary[column].get(key, column)
    
    def get_confidence(self, column: str) -> float:
        """L·∫•y ƒë·ªô tin c·∫≠y c·ªßa AI inference"""
        if column not in self.dictionary:
            return 0.0
        return self.dictionary[column].get('confidence', 0.0)
    
    def get_category(self, column: str) -> str:
        """L·∫•y category c·ªßa c·ªôt"""
        if column not in self.dictionary:
            return 'other'
        return self.dictionary[column].get('category', 'other')
    
    def to_context_string(self) -> str:
        """
        Chuy·ªÉn dictionary th√†nh string ƒë·ªÉ d√πng l√†m context cho AI
        
        Returns:
            str: Formatted string v·ªõi √Ω nghƒ©a c√°c c·ªôt
        """
        lines = ["Column Dictionary:"]
        for col, info in self.dictionary.items():
            lines.append(f"- {col}: {info['meaning_vi']} ({info['category']})")
        return "\n".join(lines)
    
    def save_to_session(self):
        """L∆∞u v√†o Streamlit session state"""
        st.session_state.column_dictionary = self.dictionary
    
    def load_from_session(self):
        """Load t·ª´ Streamlit session state"""
        if 'column_dictionary' in st.session_state:
            self.dictionary = st.session_state.column_dictionary
    
    def export_to_json(self) -> str:
        """
        Export dictionary ra JSON string
        
        Returns:
            str: JSON string
        """
        return json.dumps(self.dictionary, ensure_ascii=False, indent=2)
    
    def import_from_json(self, json_str: str):
        """
        Import dictionary t·ª´ JSON string
        
        Args:
            json_str: JSON string
        """
        self.dictionary = json.loads(json_str)
    
    @classmethod
    def from_json(cls, json_str: str, df: pd.DataFrame, model):
        """
        T·∫°o ColumnDictionary t·ª´ JSON string
        
        Args:
            json_str: JSON string
            df: DataFrame
            model: Gemini model
        
        Returns:
            ColumnDictionary instance
        """
        instance = cls(df, model)
        instance.import_from_json(json_str)
        return instance
    
    def get_summary_stats(self) -> Dict[str, Any]:
        """L·∫•y th·ªëng k√™ t·ªïng quan v·ªÅ dictionary"""
        total_columns = len(self.dictionary)
        user_edited = sum(1 for info in self.dictionary.values() if info.get('user_edited', False))
        avg_confidence = sum(info.get('confidence', 0) for info in self.dictionary.values()) / total_columns if total_columns > 0 else 0
        
        categories = {}
        for info in self.dictionary.values():
            cat = info.get('category', 'other')
            categories[cat] = categories.get(cat, 0) + 1
        
        return {
            'total_columns': total_columns,
            'user_edited': user_edited,
            'ai_inferred': total_columns - user_edited,
            'avg_confidence': round(avg_confidence, 2),
            'categories': categories
        }


def initialize_column_dictionary(df: pd.DataFrame) -> ColumnDictionary:
    """
    Initialize ho·∫∑c load Column Dictionary t·ª´ session state
    
    Args:
        df: DataFrame
    
    Returns:
        ColumnDictionary instance
    """
    from gemini_assistant import model
    
    # Check if already exists in session
    if 'column_dict_obj' in st.session_state:
        col_dict = st.session_state.column_dict_obj
        # Update df if changed
        col_dict.df = df
        return col_dict
    
    # Create new instance
    col_dict = ColumnDictionary(df, model)
    
    # Try to load from session state
    col_dict.load_from_session()
    
    # If empty, run auto-detection
    if not col_dict.dictionary:
        with st.spinner("ü§ñ AI ƒëang ph√¢n t√≠ch √Ω nghƒ©a c√°c c·ªôt..."):
            col_dict.auto_detect_meanings()
            col_dict.save_to_session()
    
    # Save object to session
    st.session_state.column_dict_obj = col_dict
    
    return col_dict
